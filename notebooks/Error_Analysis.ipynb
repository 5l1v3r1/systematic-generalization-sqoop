{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import h5py\n",
    "import json\n",
    "import torch\n",
    "from matplotlib import pyplot\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from collections import defaultdict as ddict\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/data/milatmp1/bahdanau/flatqa-letters/long-tail/'\n",
    "model_output_path = '/u/murtyjay/nmn-iwp/outputs/output_mac4.h5'\n",
    "\n",
    "def parse_dat(data_root, part):\n",
    "  features_path = data_root + part + 'features.h5'\n",
    "  with h5py.File(features_path) as src:\n",
    "    features = src['features'][:]\n",
    "    \n",
    "  data_path = data_root + part + 'questions.h5'\n",
    "  with h5py.File(data_path) as src:\n",
    "    questions = src['questions'][:]\n",
    "    answers = src['answers'][:]\n",
    "    image_idxs = src['image_idxs'][:]\n",
    "  \n",
    "  with open(data_root + 'vocab.json') as src:\n",
    "    vocab = json.load(src)\n",
    "    question_idx_to_token = {v: k for k, v in vocab['question_token_to_idx'].items()}\n",
    "    answer_idx_to_token = {v: k for k, v in vocab['answer_token_to_idx'].items()}  \n",
    "  return features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token\n",
    "\n",
    "def get_question_distribution(train_questions):\n",
    "  relation_count = ddict(int)\n",
    "  object_count = ddict(int)\n",
    "  object_pairwise_count = ddict(int)\n",
    "\n",
    "  for question in train_questions:\n",
    "    relation_count[question[5]] += 1.0\n",
    "    object_count[ question[4] ] += 1.0\n",
    "    object_count[question[7]] += 1.0\n",
    "    object_pairwise_count[(question[4], question[7])] += 1.0\n",
    "\n",
    "  return relation_count, object_count, object_pairwise_count\n",
    "\n",
    "train_features, train_questions, train_answers, train_image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root, 'train_')\n",
    "relation_count, object_count, object_pairwise_count = get_question_distribution(train_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is there a blue D right_of blue A\n",
      "is there a blue D below purple A\n",
      "is there a yellow A left_of purple C\n",
      "is there a gray A left_of purple B\n",
      "is there a purple N below yellow C\n",
      "is there a brown C right_of purple A\n",
      "is there a green E below purple D\n",
      "is there a purple D right_of yellow F\n",
      "is there a yellow D below gray C\n",
      "is there a red F left_of yellow D\n",
      "None\n",
      "defaultdict(<class 'int'>, {40: 250051.0, 41: 250109.0, 42: 249960.0, 43: 249880.0})\n"
     ]
    }
   ],
   "source": [
    "def pprint_question(questions, vocab):\n",
    "  for q in questions:\n",
    "    print(' '.join([vocab[idx] for idx in q]))\n",
    "\n",
    "print(pprint_question(train_questions[:10], question_idx_to_token))\n",
    "print(relation_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_image(img, features):\n",
    "  image = np.array(PIL.Image.open(io.BytesIO(features[img]) ))\n",
    "  pyplot.figure(figsize=(5, 5))\n",
    "  pyplot.imshow(image, origin='lower')\n",
    "  pyplot.show()\n",
    "\n",
    "    \n",
    "      \n",
    "\n",
    "\n",
    "def get_confusion_matrix(model_path, data_root, correct = None):\n",
    "\n",
    "  if correct is None:\n",
    "    with h5py.File(model_path) as src:\n",
    "      correct = src['correct'].value\n",
    "    \n",
    "  features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "  confusion = {'TP' : 0.0, 'FP' : 0.0, 'FN' : 0.0, 'TN' : 0.0}\n",
    "  acc = 0.0\n",
    "  for i in range(1000):\n",
    "\n",
    "    if answer_idx_to_token[answers[i]] == 'false':\n",
    "      confusion['TN'] += 1.0\n",
    "      if not correct[i]: confusion['FP'] += 1.0 \n",
    "          \n",
    "    else:\n",
    "      confusion['TP'] += 1.0\n",
    "      if not correct[i]: \n",
    "        confusion['FN'] += 1.0\n",
    "        #print_image(image_idxs[i])\n",
    "        #question_tokens = ' '.join([question_idx_to_token[idx] for idx in questions[i]])\n",
    "        #print(question_tokens,  answer_idx_to_token[answers[i]])\n",
    "  \n",
    "        \n",
    "    if correct[i]: \n",
    "      acc += 1.0\n",
    "      continue\n",
    "\n",
    "  return confusion\n",
    "\n",
    "\n",
    "def get_pr(confusion_matrix):\n",
    "    p = confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FP'])\n",
    "    r = confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FN'])\n",
    "    return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "/u/murtyjay/nmn-iwp/outputs/output_film1.h5\n",
      "(0.9191176470588235, 0.9861932938856016)\n",
      "2\n",
      "/u/murtyjay/nmn-iwp/outputs/output_film2.h5\n",
      "(0.9057971014492754, 0.9823182711198428)\n",
      "3\n",
      "/u/murtyjay/nmn-iwp/outputs/output_film3.h5\n",
      "(0.9174311926605505, 0.9900990099009901)\n",
      "4\n",
      "/u/murtyjay/nmn-iwp/outputs/output_film4.h5\n",
      "(0.9276437847866419, 0.9920634920634921)\n",
      "5\n",
      "/u/murtyjay/nmn-iwp/outputs/output_film5.h5\n",
      "(0.9157509157509157, 0.9940357852882704)\n"
     ]
    }
   ],
   "source": [
    "# CONFUSION MATRIX ANALYSIS\n",
    "\n",
    "model_output_path = '/u/murtyjay/nmn-iwp/outputs/output_film'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(i)\n",
    "    file=\"%s%s.h5\" %(model_output_path, i)\n",
    "    print(file)\n",
    "    cm = get_confusion_matrix(file , data_root )\n",
    "    print(get_pr(cm))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0.886\n"
     ]
    }
   ],
   "source": [
    "# identify answers based on just color information\n",
    "\n",
    "freq_letter = lambda tok : question_idx_to_token[tok] in list(string.ascii_uppercase)[:6]\n",
    "rare_letter = lambda tok : not freq_letter(tok) \n",
    "\n",
    "\n",
    "def read_json(data_root, part):\n",
    "  json_data=open('%s/%s_scenes.json' %(data_root, part)).read()\n",
    "  data = json.loads(json_data)\n",
    "  return data\n",
    "\n",
    "\n",
    "class ColorOnlyBaseline(object):\n",
    "    def fit(self, data_root):\n",
    "      self.json_reps = {}\n",
    "      self.json_reps['train'] = read_json(data_root, 'train')\n",
    "      self.json_reps['test']  = read_json(data_root, 'test')\n",
    "      self.json_reps['val']   = read_json(data_root, 'val')\n",
    "    \n",
    "    def classify(self, question, idx, split):\n",
    "      curr_img_colors = [obj['color'] for obj in self.json_reps[split][idx]]\n",
    "      colors = question_idx_to_token[question[3]], question_idx_to_token[question[6]]\n",
    "   \n",
    "      return colors[0] in curr_img_colors and colors[1] in curr_img_colors   \n",
    "    \n",
    "class ColorAndShapeBaseline(object):\n",
    "    def fit(self, data_root):\n",
    "      self.json_reps = {}\n",
    "      self.json_reps['train'] = read_json(data_root, 'train')\n",
    "      self.json_reps['test']  = read_json(data_root, 'test')\n",
    "      self.json_reps['val']   = read_json(data_root, 'val')\n",
    "    \n",
    "    def classify(self, question, idx, split):\n",
    "      curr_img_colAndshape = [(obj['color'], obj['shape']) for obj in self.json_reps[split][idx]]\n",
    "      lobj = (question_idx_to_token[question[3]], question_idx_to_token[question[4]])\n",
    "      robj = (question_idx_to_token[question[6]], question_idx_to_token[question[7]])\n",
    "        \n",
    "      return lobj in curr_img_colAndshape and robj in curr_img_colAndshape\n",
    "\n",
    "class ColorAndShapeTypeBaseline(object):\n",
    "    def fit(self, data_root):\n",
    "      self.json_reps = {}\n",
    "      self.json_reps['train'] = read_json(data_root, 'train')\n",
    "      self.json_reps['test']  = read_json(data_root, 'test')\n",
    "      self.json_reps['val']   = read_json(data_root, 'val')\n",
    "    \n",
    "    def classify(self, question, idx, split):\n",
    "      curr_img_colAndshape = [(obj['color'], obj['shape'] in list(string.ascii_uppercase)[:6] ) for obj in self.json_reps[split][idx]]\n",
    "      lobj = (question_idx_to_token[question[3]], freq_letter(question[4]) )\n",
    "      robj = (question_idx_to_token[question[6]], freq_letter(question[7]) )\n",
    "        \n",
    "      return lobj in curr_img_colAndshape and robj in curr_img_colAndshape\n",
    "\n",
    "color_only_bot = ColorAndShapeBaseline()\n",
    "color_only_bot.fit(data_root)\n",
    "features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "\n",
    "\n",
    "colorOnlyBaseline_correct = [color_only_bot.classify(question, _id,  'val') == answers[_id] for (_id, question) in enumerate(questions[:1000])]\n",
    "print(len(colorOnlyBaseline_correct))\n",
    "acc = sum(colorOnlyBaseline_correct) / 1000.0\n",
    "print(acc)\n",
    "hard_questions = [idx for idx in range(1000) if not colorOnlyBaseline_correct[idx]]\n",
    "#print(get_confusion_matrix(None, data_root, colorOnlyBaseline_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963\n",
      "0.969\n",
      "0.963\n",
      "0.955\n",
      "0.955\n",
      "0.53665631459995\n",
      "0.9525368248772506 0.961\n"
     ]
    }
   ],
   "source": [
    "# OOV analysis \n",
    "\n",
    "\n",
    "\n",
    "freq_freq_factor = lambda question, img :  freq_letter(question[4])  and freq_letter(question[7])\n",
    "rare_rare_factor = lambda question, img :  rare_letter(question[4]) and rare_letter(question[7])\n",
    "freq_rare_factor = lambda question, img : (rare_letter(question[4]) and freq_letter(question[7])) or (freq_letter(question[4]) and rare_letter(question[7])) \n",
    "\n",
    "model_output_path = '/u/murtyjay/nmn-iwp/outputs/output_ee'\n",
    "\n",
    "\n",
    "def get_incorrect_questions(model_path, data_root):\n",
    "  with h5py.File(model_path) as src:\n",
    "    correct = src['correct'].value\n",
    "  incorrect_ques = []\n",
    "  features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "\n",
    "  for i in range(1000):\n",
    "    if not correct[i]:\n",
    "        ques = questions[i]\n",
    "        \n",
    "    \n",
    "    \n",
    "def get_factor_posterior(model_path, data_root, factor):\n",
    "  with h5py.File(model_path) as src:\n",
    "    correct = src['correct'].value\n",
    "    \n",
    "  features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "  factor_and_incorrect = 0.0\n",
    "  factor_and_correct = 0.0\n",
    "  prob_factor = 0.0\n",
    "\n",
    "  for i in range(1000): \n",
    "    question = questions[i]\n",
    "    factor_val = factor(question, image_idxs[i])\n",
    "    \n",
    "    prob_factor += factor_val\n",
    "    if correct[i]: factor_and_correct += factor_val\n",
    "    else: factor_and_incorrect += factor_val\n",
    "    \n",
    "  prob_factor_given_correct   = factor_and_correct   / sum(correct)\n",
    "  prob_factor_given_incorrect = factor_and_incorrect / (1000.0 - sum(correct))\n",
    "  prob_factor = prob_factor / 1000.0\n",
    "  return prob_factor_given_correct ,  prob_factor_given_incorrect , prob_factor\n",
    "\n",
    "def get_correct_given_factor(model_path, data_root, factor):\n",
    "  with h5py.File(model_path) as src:\n",
    "    correct = src['correct'].value\n",
    "    \n",
    "  features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "  factor_true_dat = 0.0\n",
    "  factor_total = 0.0\n",
    "  factor_true_list = []\n",
    "  acc = []\n",
    "    \n",
    "    \n",
    "    \n",
    "  for i in range(1000): \n",
    "    question = questions[i]\n",
    "    acc.append( correct[i])\n",
    "    factor_val = factor(question, image_idxs[i])\n",
    "    if factor_val:\n",
    "        factor_true_dat += correct[i]\n",
    "        factor_total += 1.0\n",
    "        factor_true_list.append(i)\n",
    "    \n",
    "\n",
    "  return factor_true_dat / factor_total , 1.0*sum(acc)/len(acc), factor_true_list\n",
    "\n",
    "\n",
    "\n",
    "def get_factor_samples(model_path, data_root, factor_list):\n",
    "  with h5py.File(model_path) as src:\n",
    "    correct = src['correct'].value\n",
    "    \n",
    "  features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "\n",
    "  confusion = {'TP' : 0.0, 'FP' : 0.0, 'FN' : 0.0, 'TN' : 0.0}\n",
    "        \n",
    "  for _id in factor_list:\n",
    "    question = questions[_id]\n",
    "    if answer_idx_to_token[answers[_id]] == 'false':\n",
    "      confusion['TN'] += 1.0\n",
    "      if not correct[_id]: confusion['FP'] += 1.0 \n",
    "          \n",
    "    else:\n",
    "      confusion['TP'] += 1.0\n",
    "      if not correct[_id]: \n",
    "        confusion['FN'] += 1.0\n",
    "        \n",
    "    if correct[_id]:\n",
    "      print(' '.join([question_idx_to_token[idx] for idx in question]), bool(answers[_id]))\n",
    "      print_image(image_idxs[_id], features)\n",
    "\n",
    "  print(confusion)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "avg_condtioned_accuracy = 0.0\n",
    "avg_overall_accuracy = []\n",
    "for i in range(1, 6):\n",
    "    file=\"%s%s.h5\" %(model_output_path, i)\n",
    "    #prob_factor_given_correct , prob_factor_given_incorrect , prob_factor  = get_factor_posterior(file , data_root, rare_rare_factor )\n",
    "  \n",
    "    prob_correct_given_factor, prob_correct, factor_list = get_correct_given_factor(file, data_root, rare_rare_factor)\n",
    "    #get_factor_samples(file, data_root, factor_list)\n",
    "    #print(prob_factor, prob_factor_given_incorrect, prob_factor - prob_factor_given_correct,  prob_factor - prob_factor_given_incorrect)\n",
    "    \n",
    "    avg_condtioned_accuracy += prob_correct_given_factor\n",
    "    avg_overall_accuracy .append( prob_correct)\n",
    "    print(prob_correct)\n",
    "\n",
    "print(np.std(avg_overall_accuracy)*100.0)\n",
    "print(avg_condtioned_accuracy/5, 1.0*sum(avg_overall_accuracy)/len(avg_overall_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05325443786982249"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6. * 6 / 26 / 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
