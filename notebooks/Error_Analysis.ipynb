{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import h5py\n",
    "import json\n",
    "import torch\n",
    "from matplotlib import pyplot\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict as ddict\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/data/milatmp1/bahdanau/flatqa-letters/long-tail/'\n",
    "model_output_path = '/u/murtyjay/nmn-iwp/outputs/output_mac4.h5'\n",
    "\n",
    "def parse_dat(data_root, part):\n",
    "  features_path = data_root + part + 'features.h5'\n",
    "  with h5py.File(features_path) as src:\n",
    "    features = src['features'][:]\n",
    "    \n",
    "  data_path = data_root + part + 'questions.h5'\n",
    "  with h5py.File(data_path) as src:\n",
    "    questions = src['questions'][:]\n",
    "    answers = src['answers'][:]\n",
    "    image_idxs = src['image_idxs'][:]\n",
    "  \n",
    "  with open(data_root + 'vocab.json') as src:\n",
    "    vocab = json.load(src)\n",
    "    question_idx_to_token = {v: k for k, v in vocab['question_token_to_idx'].items()}\n",
    "    answer_idx_to_token = {v: k for k, v in vocab['answer_token_to_idx'].items()}  \n",
    "  return features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token\n",
    "\n",
    "def get_question_distribution(train_questions):\n",
    "  relation_count = ddict(int)\n",
    "  object_count = ddict(int)\n",
    "  object_pairwise_count = ddict(int)\n",
    "\n",
    "  for question in train_questions:\n",
    "    relation_count[question[5]] += 1.0\n",
    "    object_count[(question[3], question[4])] += 1.0\n",
    "    object_count[(question[6], question[7])] += 1.0\n",
    "    object_pairwise_count[(question[3], question[4], question[6], question[7])] += 1.0\n",
    "\n",
    "  return relation_count, object_count, object_pairwise_count\n",
    "\n",
    "train_features, train_questions, train_answers, train_image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root, 'train_')\n",
    "relation_count, object_count, object_pairwise_count = get_question_distribution(train_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is there a blue D right_of blue A\n",
      "is there a blue D below purple A\n",
      "is there a yellow A left_of purple C\n",
      "is there a gray A left_of purple B\n",
      "is there a purple N below yellow C\n",
      "is there a brown C right_of purple A\n",
      "is there a green E below purple D\n",
      "is there a purple D right_of yellow F\n",
      "is there a yellow D below gray C\n",
      "is there a red F left_of yellow D\n",
      "None\n",
      "defaultdict(<class 'int'>, {40: 250051.0, 41: 250109.0, 42: 249960.0, 43: 249880.0})\n"
     ]
    }
   ],
   "source": [
    "def pprint_question(questions, vocab):\n",
    "  for q in questions:\n",
    "    print(' '.join([vocab[idx] for idx in q]))\n",
    "\n",
    "print(pprint_question(train_questions[:10], question_idx_to_token))\n",
    "print(relation_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_image(img):\n",
    "  image = np.array(PIL.Image.open(io.BytesIO(features[img]) ))\n",
    "  pyplot.figure(figsize=(5, 5))\n",
    "  pyplot.imshow(image, origin='lower')\n",
    "  pyplot.show()\n",
    "\n",
    "    \n",
    "    \n",
    "features, questions, answers, image_idxs, _, _, _ = parse_dat(data_root, part)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "def get_confusion_matrix(model_path, data_root):\n",
    "  with h5py.File(model_path) as src:\n",
    "    correct = src['correct'].value\n",
    "    \n",
    "  features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "  confusion = {'TP' : 0.0, 'FP' : 0.0, 'FN' : 0.0, 'TN' : 0.0}\n",
    "  acc = 0.0\n",
    "  for i in range(1000):\n",
    "\n",
    "    if answer_idx_to_token[answers[i]] == 'false':\n",
    "      confusion['TN'] += 1.0\n",
    "      if not correct[i]: confusion['FP'] += 1.0 \n",
    "          \n",
    "    else:\n",
    "      confusion['TP'] += 1.0\n",
    "      if not correct[i]: \n",
    "        confusion['FN'] += 1.0\n",
    "        #print_image(image_idxs[i])\n",
    "        #question_tokens = ' '.join([question_idx_to_token[idx] for idx in questions[i]])\n",
    "        #print(question_tokens,  answer_idx_to_token[answers[i]])\n",
    "  \n",
    "        \n",
    "    if correct[i]: \n",
    "      acc += 1.0\n",
    "      continue\n",
    "\n",
    "  return confusion\n",
    "\n",
    "\n",
    "def get_pr(confusion_matrix):\n",
    "    p = confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FP'])\n",
    "    r = confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FN'])\n",
    "    return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "/u/murtyjay/nmn-iwp/outputs/output_mac1.h5\n",
      "(0.7668711656441718, 0.9823182711198428)\n",
      "2\n",
      "/u/murtyjay/nmn-iwp/outputs/output_mac2.h5\n",
      "(0.7874015748031497, 0.9689922480620154)\n",
      "3\n",
      "/u/murtyjay/nmn-iwp/outputs/output_mac3.h5\n",
      "(0.78125, 0.9920634920634921)\n",
      "4\n",
      "/u/murtyjay/nmn-iwp/outputs/output_mac4.h5\n",
      "(0.8561643835616438, 0.9727626459143969)\n",
      "5\n",
      "/u/murtyjay/nmn-iwp/outputs/output_mac5.h5\n",
      "(0.7923930269413629, 0.9523809523809523)\n"
     ]
    }
   ],
   "source": [
    "# CONFUSION MATRIX ANALYSIS\n",
    "\n",
    "model_output_path = '/u/murtyjay/nmn-iwp/outputs/output_mac'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(i)\n",
    "    file=\"%s%s.h5\" %(model_output_path, i)\n",
    "    print(file)\n",
    "    cm = get_confusion_matrix(file , data_root )\n",
    "    print(get_pr(cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV analysis \n",
    "\n",
    "model_output_path = '/u/murtyjay/nmn-iwp/outputs/output_film'\n",
    "def get_object_counts(model_path, data_root):\n",
    "  with h5py.File(model_path) as src:\n",
    "    correct = src['correct'].value\n",
    "    \n",
    "  features, questions, answers, image_idxs, vocab, question_idx_to_token, answer_idx_to_token = parse_dat(data_root,'val_')\n",
    "  object_pair_counts = []\n",
    "  inv_object_pair_counts = []\n",
    "  for i in range(1000): \n",
    "    question = questions[i]\n",
    "    if not correct[i]: \n",
    "      lobject = (question[3], question[4])\n",
    "      robject = (question[6], question[7])\n",
    "      object_pair = (*lobject, *robject)\n",
    "      inv_object_pair = (*robject, *lobject)\n",
    "      object_pair_counts.append(object_pairwise_count[object_pair])\n",
    "      inv_object_pair_counts.append(object_pairwise_count[inv_object_pair])\n",
    "    \n",
    "\n",
    "  return object_pair_counts,inv_object_pair_counts   \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(i)\n",
    "    file=\"%s%s.h5\" %(model_output_path, i)\n",
    "    oc, inv_oc = get_object_counts(file , data_root )\n",
    "    #oc = Counter(oc)\n",
    "    #inv_oc = Counter(inv_oc)\n",
    "    \n",
    "    #bins, items = (list(zip(*sorted(oc.items()))))\n",
    "    #print(bins, items)\n",
    "    #pyplot.hist(items, [int(bin) for bin in bins])\n",
    "    print(oc)\n",
    "    print(inv_oc)\n",
    "    #pyplot.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
